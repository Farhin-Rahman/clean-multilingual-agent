# LLM router (keep if you run Ollama locally)
OLLAMA_URL=http://localhost:11434/api/chat

# sentiment engine: auto | finbert | vader
SENTIMENT_ENGINE=auto

# optional: move RAG index dirs if you like
# RAG_TEXT_DIR=.rag/text_index
# RAG_LOGIC_DIR=.rag/logic_index

GROQ_API_KEY=dummy_value
